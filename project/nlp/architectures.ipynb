{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectures\n",
    "- Recurrent Neural Networks (RNN)\n",
    "- Long Short-Term Memory Networks (LSTM)\n",
    "- Gated Recurrent Units (GRU)\n",
    "- Convolutional Neural Networks (CNN) for text classification\n",
    "- Bidirectional Encoder Representations from Transformers (BERT)\n",
    "- Generative Pre-trained Transformer (GPT)\n",
    "- Transformers (general)\n",
    "- Attention Mechanism-based Models\n",
    "- Sequence-to-Sequence (Seq2Seq) Models\n",
    "- Hierarchical Attention Networks (HAN)\n",
    "- TextCNN\n",
    "- FastText\n",
    "- ELMo (Embeddings from Language Models)\n",
    "- ULMFiT (Universal Language Model Fine-tuning)\n",
    "- XLNet\n",
    "- RoBERTa\n",
    "- ALBERT\n",
    "- T5 (Text-to-Text Transfer Transformer)\n",
    "- DistilBERT\n",
    "- Electra"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
